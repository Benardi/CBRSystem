---
title: "Case Based Reasoning System for MSRP estimation"
output:
    html_document:
    df_print: paged
theme: sandstone
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(here)
library(FNN)
library(class)
library(magrittr)

theme_set(theme_bw())
```

## Loading Data

```{r}
read_csv(here("data/data.csv"),
         progress = FALSE, 
         col_types =
           cols(
            Make = col_character(),
            Model = col_character(),
            Year = col_integer(),
            `Engine Fuel Type` = col_character(),
            `Engine HP` = col_integer(),
            `Engine Cylinders` = col_integer(),
            `Transmission Type` = col_character(),
            Driven_Wheels = col_character(),
            `Number of Doors` = col_integer(),
            `Market Category` = col_character(),
            `Vehicle Size` = col_character(),
            `Vehicle Style` = col_character(),
            `highway MPG` = col_integer(),
            `city mpg` = col_integer(),
            Popularity = col_integer(),
            MSRP = col_integer()
            )) %>% 
  drop_na() -> car_data 

car_data %>% 
    glimpse()
```

### Checking for missing values

```{r}
row.has.na <- apply(car_data, 
                    1,
                    function(x){any(is.na(x))})
noquote(paste('Number of rows with misssing values: ',
            sum(row.has.na)))
```

## Remove Categorical variables

```{r}
# dummified <- fastDummies::dummy_columns(car_data)
```

```{r}
## Removing categorical variables for now

num.vars <- sapply(car_data,
                   is.numeric)

car_data <- car_data[num.vars]


## Applying scale to numeric variables except MSRP

num.vars <- sapply(car_data,
                   is.numeric, 
                   simplify=F)

num.vars$MSRP = FALSE
num.vars <- unlist(num.vars)

car_data[num.vars] <- lapply(car_data[num.vars],
                             scale)
```

## Split data into training/testing sets 

```{r}
set.seed(101)

## Adding surrogate key to dataframe
car_data$id <- 1:nrow(car_data)

car_data %>% 
  dplyr::sample_frac(.8) -> train

dplyr::anti_join(car_data, 
                 train, 
                 by = 'id') -> test
```

```{r}
dplyr::semi_join(test, 
                 train, 
                 by = 'id') 
```


## Dissociating predictor from response variable and surrogate key

```{r}
train %>% 
  select(-MSRP,-id) -> train.predictors

train %>% 
  select(MSRP, id) -> train.response

test %>% 
  select(-MSRP,-id) -> test.predictors

test %>% 
  select(MSRP, id) -> test.response
```


### Choosing K Nearest Neighbor  for K = 10

```{r}
require(FNN)

calc_KNN_error <- function(k_val = n, 
                           indices = indices, 
                           train = train.response,
                           test = test) {
  
  k <- FNN::knn(train.predictors,
              test.predictors, 
              train.response$id,
              k = k_val,
              algorithm="cover_tree")

  indices <- attr(k, "nn.index")
  
  estimates <- c()
  
  for(i in seq(1,nrow(indices),1)) {
    lapply(indices[i,],
         function(x){train.response[x,]$MSRP}) %>% 
    Reduce("+", .) %>% 
    divide_by(length(indices[i,])) -> result
    estimates <-c(estimates, result)
  }
  
  accum_error <- 0
  
  for(j in seq(1,length(estimates),1)) {
    accum_error <- accum_error + ((estimates[j] - test$MSRP[j]) ^ 2 )
  }
  return(accum_error)
}
```

```{r}
calc_KNN_error(k = 10,
               indices = indices,
               train = train.response,
               test = test) 
```



